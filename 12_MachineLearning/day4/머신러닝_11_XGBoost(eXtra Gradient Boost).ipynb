{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost(eXtra Gradient Boost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost 개요\n",
    "- 트리 기반의 앙상블 학습 알고리즘 \n",
    "- 분류에 있어서 일반적으로 다른 머신러닝보다 뛰어난 예측 성능을 나타냄\n",
    "- GBM에 기반"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost 장점\n",
    "- 뛰어난 예측 성능\n",
    "- GBM 대비 빠른 수행 시간\n",
    "- 과적합 규제 \n",
    "- 가지치기 (pruning)\n",
    "- 교차 검증 내장\n",
    "- 결측값 자체 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost 라이브러리\n",
    "\n",
    "(1) XGBoost는 처음에는 C/C++로 작성되었음\n",
    "\n",
    "(2) 파이썬에서도 XGBoost를 구동할 수 있도록 파이썬 패키지 **`xgboost`** 제공\n",
    "- 패키지 역할 : 대부분 C/C++ 핵심 라이브러리를 호출하는 것\n",
    "- 사이킷런과 호환되지 않는 독자적인 XGBoost 전용 패키지\n",
    "- 사이킷런의 fit(), predict() 메서드 같은 사이킷런 고유 아키텍처 적용 불가\n",
    "- 다양한 유틸리티(cross_val_score, GridSearchCV, Pipeline 등)도 사용 불가\n",
    "- **`'파이썬 래퍼 XGBoost 모듈'`**로 지칭\n",
    "\n",
    "(3) 파이썬 기반의 ML 이용자들이 사이킷런을 많이 사용하기 때문에  \n",
    "사이킷런과 연동할 수 있는 래퍼 클래스(Wrapper class) 제공\n",
    "- **`XGBClassifer`** 와 **`XGBRegressor`** 래퍼 클래스\n",
    "- 사이킷런 estimator가 학습을 위해 사용하는 fit()과 predict() 등 \n",
    "- 표준 사이킷런 개발 프로세스 및 다양한 유틸리티 활용 가능\n",
    "- **`'사이킷런 래퍼 XGBoost 모듈'`** 로 지칭"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과적합 문제가 심각한 경우 XGBoost에서 하이퍼파라미터 튜닝\n",
    "- eta 값 낮추고 num_round(또는 n_estimators)는 반대로 높임\n",
    "- max_depth 값 낮춤\n",
    "- min_child_weight 값 높임\n",
    "- gamma 값 높임 (?)\n",
    "- subsample과 colsample_bytree 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost 조기 중단(Early Stopping) 기능\n",
    "- 지정한 수만큼의 부스팅 반복 작업이 종료되지 않더라도 예측 오류가 더 이상 개선되지 않으면 중간에 중지해서 수행 시간 개선 \n",
    "\n",
    "- 학습 시간 단축 : 특히 최적화 튜닝 단계에서 적절하게 사용 가능\n",
    "\n",
    "- 반복 횟수를 많이 단축할 경우 예측 성능 최적화가 안 된 상태에서 학습이 종료될 수 있으므로 주의 필요\n",
    "\n",
    "- 조기 중단 설정을 위한 주요 파라미터\n",
    "    - early_stoppings \n",
    "    - eval_metric \n",
    "    - eval_set "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost 설치\n",
    "- Windows 기반에서 설치하는 경우\n",
    "    * Anaconda Prompt 관리자 모드로 열고  \n",
    "    * conda install -c anaconda py-xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost 버전 확인\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost : XGBoost의 파이썬 패키지\n",
    "- 자체적으로 교차 검증, 성능 평가, 피처 중요도 등의 시각화 기능 포함\n",
    "- 조기 중단 기능 : 수행 시간 개선 \n",
    "- 빠른 수행시간 처리 가능하지만\n",
    "- CPU 코어가 많지 않은 개인용 PC에서는 수행시간 향상 효과 보기 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이썬 래퍼 XGBoost 하이퍼파라미터\n",
    "\n",
    "① 일반 파라미터 : 실행 시 스레드의 개수, silent 모드 등의 선택을 위한 파라미터로 거의 바꾸는 경우 없음\n",
    "\n",
    "② 부스터 파라미터 : 트리 최적화, 부스팅, regularization 등과 관련된 파라미터\n",
    "\n",
    "③ 학습 태스크 파라미터 : 학습 수행 시 객체 함수, 평가를 위한 지표 등을 설정하는 파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과적합 문제가 심각할 경우 파이썬래퍼 XGBoost의 조정할 하이퍼 파라미터들\n",
    "- eta값을 낮춤 (0.01 ~ 0.2) : num_round(또는 n_estimator)는 반대로 높여줘야 함\n",
    "- max_depth 값을 낮춤\n",
    "- min_child_weight 값을 높임\n",
    "- gamma 값을 높임\n",
    "- subsample과 colsample_bytree 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사이킷런 래퍼 XGBoost\n",
    "- 사이킷런의 기본 Estimator를 그대로 상속해 만든 것\n",
    "- 다른 estimator와 같이 **`fit(), predict()`**만으로 학습과 예측 가능\n",
    "- GridSearchCV, Pipeline 등 사이킷런의 유틸리티 그대로 사용 가능\n",
    "\n",
    "\n",
    "- 분류를 위한 XGBClassifier 클래스\n",
    "- 회귀를 위한 XGBRegressor 클래스\n",
    "\n",
    "\n",
    "- 파이썬 래퍼 XGBoost에서 사용하는 하이퍼파라미터와 호환성을 유지하기 위해 몇개 하이퍼파라미터를 변경\n",
    "    - eta  → learning_rate\n",
    "    - sub_sample → subsample\n",
    "    - lambda → reg_lambda\n",
    "    - alpha → reg_alpha\n",
    "    \n",
    "    \n",
    "- xgboost의 n_estimators와 num_boost_round는 동일한 파라미터\n",
    "    - 이를 동시에 사용할 경우 \n",
    "        - 파이썬 래퍼 XGBoost API는 n_estimator를 무시하고 num_boost_round를 적용\n",
    "        - 사이킷런 래퍼 XGBoost는 n_estimator 파라미터를 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [예제] 위스콘신 유방암 예측  \n",
    "(1) 파이썬 Wrapper XGBoost 적용  \n",
    "(2) 사이킷런 Wrapper XGBoost 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위스콘신 유방암 데이터 세트\n",
    ": 사이킷런 내장데이터세트 `load_brest_cancer`\n",
    "- 종양의 크기, 모양 등의 다양한 속성값을 기반으로\n",
    "- 악성 종양(malignant)인지 양성 종양(benign)인지를 분류한 세트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 파이썬 래퍼 XGBoost 적용 – 위스콘신 Breast Cancer 데이터 셋\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모둘 임포트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 세트 로딩 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확인하기 위해 데이터 프레임으로 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 맨 마지막에 target 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 값 분포 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터 추출\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**학습과 예측 데이터 세트를 `DMatrix`로 변환** \n",
    "\n",
    "- 파이썬 래퍼 XGBoost에서는 사이킷런과 다르게 별도로 DMatrix 사용   \n",
    "- DMatrix : XGBoost 전용 데이터 세트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DMatrix 타입으로 변환: 학습용, 테스트용 데이터 세트 생성\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**하이퍼 파라미터 설정**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**테스트 데이터 세트에 예측 수행**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost 모델의 예측 성능 평가**\n",
    ":앞의 평가에서 생성한 get_clf_eval( ) 함수 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost 패키지에 내장된 시각화 기능 이용하여 피처 중요도 시각화\n",
    "\n",
    "- plot_importance() API : 피처의 중요도를 막대그래프 형식으로 나타냄\n",
    "    - 기본 평가 지표로 fi 스코어를 기반으로 해서 \n",
    "    - 각 피처의 중요도 표시\n",
    "\n",
    "**`plot_importance(학습이 완료된 모델 객체, Matplotlib의 ax)`**\n",
    "    \n",
    "(사이킷런 : Estimator 객체의 feature_importance_ 속성을 이용해 시각화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**graphviz를 이용하여 XGBoosts 모델 트리 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이썬 래퍼 XGBoost 교차검증 수행 API : cv()\n",
    "\n",
    ": xgboost는 사이킷런의 GridSearchCV와 유사하게 cv( )를 API로 제공"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "xgb.cv(params, dtrain, num_boost_round=10, nfold=3, stratified=False,\n",
    "        folds=None, metrics=(),obj=None, feval=None, maximize=False,\n",
    "        early_stopping_rounds=None, fpreproc=None, as_pandas=True,\n",
    "        verbose_eval=None, show_stdv=True, seed=0, callbacks=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 사이킷런 Wrapper XGBoost 개요 및 적용 \n",
    "\n",
    "- 사이킷런의 기본 Estimator를 그대로 상속  \n",
    "- fit()과 predict()만드로 학습과 예측 가능  \n",
    "\n",
    "- 하이퍼 파라미터 차이  \n",
    "    - 파이썬 Wrapper : 사이킷런 Wrapper  \n",
    "        - eta : learning_rate (학습률)  \n",
    "        - num_boost_rounds : n_estimators (학습기의 개수 : 반복 수행 횟수)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 래퍼 XGBoost 클래스인 XGBClassifier 임포트\n",
    "\n",
    "\n",
    "# 학습과 예측 수행 : \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 성능 평가 수행\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**early stopping을 100으로 설정하고 재 학습/예측/평가**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping이 어떻게 동작하는지 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 성능 평가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 결과\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**early stopping을 10으로 설정하고 재학습/예측/평가**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 중요도 시각화\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
